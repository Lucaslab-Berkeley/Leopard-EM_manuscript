{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71e5c6a",
   "metadata": {},
   "source": [
    "# Slab projections of constrained 2DTM results\n",
    "\n",
    "Here, the 60S large ribosomal subunit locations and orientations are used to constrain the 2DTM search for the 40S small ribosomal subunit. \n",
    "We reuse some code for slab generation to visualize the number of 40S subunits identified in isolation compared with the 40S subunits found using the constrained search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "586db21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mrcfile\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import rotate\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# import napari\n",
    "import torch_fourier_rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29821918",
   "metadata": {},
   "source": [
    "## Downloading, importing, and loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e36bbb",
   "metadata": {},
   "source": [
    "### Load in the simulated templates\n",
    "\n",
    "Each of these volumes have been simulated and used to search a micrograph using 2DTM.\n",
    "We load the MRC files into numpy arrays and additionally find their simulated pixel sizes.\n",
    "These data will be used to downsample the volumes before placing them in the slab volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c320dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_60S_path = \"/data/papers/Leopard-EM_paper_data/maps/60S_map_px0.936_bscale0.5.mrc\"\n",
    "template_40S_path = \"/data/papers/Leopard-EM_paper_data/maps/SSU-body_map_px0.936_bscale0.5.mrc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995bccec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60S template shape: (512, 512, 512)\n",
      "60S template voxel shape: 0.936\n",
      "\n",
      "40S template shape: (512, 512, 512)\n",
      "40S template voxel shape: 0.936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load template files and print their shapes\n",
    "with mrcfile.open(template_60S_path, mode=\"r\") as f:\n",
    "    template_60S = f.data.copy()\n",
    "    px_60S = f.voxel_size.x.item()\n",
    "    print(f\"60S template shape: {template_60S.shape}\")\n",
    "    print(f\"60S template voxel shape: {px_60S:.3f}\")\n",
    "    print()\n",
    "\n",
    "with mrcfile.open(template_40S_path, mode=\"r\") as f:\n",
    "    template_40S = f.data.copy()\n",
    "    px_40S = f.voxel_size.x.item()\n",
    "    print(f\"40S template shape: {template_40S.shape}\")\n",
    "    print(f\"40S template voxel shape: {px_40S:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14922ba1",
   "metadata": {},
   "source": [
    "### Load in the full micrograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec47ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60S micrograph shape: (4096, 4096)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_path = \"/data/papers/Leopard-EM_paper_data/xe30kv/all_mgraphs/xenon_252_000_0.0_DWS.mrc\"\n",
    "\n",
    "\n",
    "with mrcfile.open(img_path, mode=\"r\") as f:\n",
    "    img = f.data.copy()\n",
    "    print(f\"60S micrograph shape: {img.shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a26dc",
   "metadata": {},
   "source": [
    "### Match template results for individual 40S and 60S searches\n",
    "\n",
    "These are csv files parsed into a DataFrame which contains all necessary information about each located particle.\n",
    "\n",
    "*Note: we apply an additional filtering step to exclude peaks within 10 pixels to avoid selecting the same particle multiple times.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef02cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_60S_df_path =   \"/data/papers/Leopard-EM_paper_data/xe30kv/results_refine_tm_60S_2/xenon_235_000_0.0_DWS_refined_results.csv\"\n",
    "results_40S_df_path = \"/data/papers/Leopard-EM_paper_data/xe30kv/results_match_tm_40S-body/xenon_235_000_0.0_DWS_results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81ebcbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_60S_df = pd.read_csv(results_60S_df_path)\n",
    "results_40S_df = pd.read_csv(results_40S_df_path)\n",
    "len(results_60S_df), len(results_40S_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebcee69",
   "metadata": {},
   "source": [
    "### Constrained orientation search results for 40S\n",
    "\n",
    "Again, this is a csv file parsed into a DataFrame with similar content, but this time the data has just been processed using the constrained search program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06245f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "constrained_40S_df_path = \"/data/papers/Leopard-EM_paper_data/xe30kv/results_all_steps_5/step_4/xenon_235_000_0.0_DWS_constrained_results_above_threshold.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da5fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 53)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constrained_40S_df = pd.read_csv(constrained_40S_df_path)\n",
    "constrained_40S_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7d9934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     100.0\n",
       "1     -20.0\n",
       "2     -80.0\n",
       "3     200.0\n",
       "4    -220.0\n",
       "      ...  \n",
       "81   -200.0\n",
       "82   -100.0\n",
       "83   -440.0\n",
       "84    280.0\n",
       "85   -240.0\n",
       "Name: refined_relative_defocus, Length: 86, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the 'refined_relative_defocus' column with that in the results_60S_df\n",
    "#\n",
    "# The rationale behind this is because the two models were aligned together, that\n",
    "# their relative z-positions should be the same. However, the 40S particle will\n",
    "# *physically* have a different defocus value than the 60S particle in the sample, thus\n",
    "# we should account for this during CTF computation since projections only happen in the\n",
    "# x-y plane.\n",
    "#\n",
    "# The 'particle_index' column maps 40S particles to 60S particles, so we can use it to\n",
    "# replace the 'refined_relative_defocus' column in the constrained_40S_df with the\n",
    "# corresponding values from the results_60S_df.\n",
    "for i, row in constrained_40S_df.iterrows():\n",
    "    particle_index = row[\"particle_index\"]\n",
    "    row_60S = results_60S_df[results_60S_df[\"particle_index\"] == particle_index]\n",
    "    if row_60S.shape[0] == 1:\n",
    "        real_df = row_60S[\"refined_relative_defocus\"].values[0]\n",
    "        constrained_40S_df.at[i, \"refined_relative_defocus\"] = real_df\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Expected one row for particle index {particle_index}, but got {row_60S.shape[0]} rows.\"\n",
    "        )\n",
    "constrained_40S_df.refined_relative_defocus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24540c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_close_results(df: pd.DataFrame, threshold: float = 10.0) -> pd.DataFrame:\n",
    "    \"\"\"Filters rows in a DataFrame based on proximity of 'pos_x' and 'pos_y' values.\n",
    "\n",
    "    NOTE: This function give preference to rows with a higher 'scaled_mip' value\n",
    "    when filtering out close results.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing 'pos_x' and 'pos_y' columns.\n",
    "    threshold : float\n",
    "        Distance threshold for filtering. Rows with 'pos_x' and 'pos_y' values\n",
    "        within this distance of each other will be filtered out.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Filtered DataFrame containing only rows that are not close to each other\n",
    "        based on the specified threshold.\n",
    "    \"\"\"\n",
    "    filtered_df = df.copy()\n",
    "    filtered_df = filtered_df.sort_values(by=\"scaled_mip\", ascending=False)\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "    # List to store indices of rows to keep\n",
    "    indices_to_keep = []\n",
    "\n",
    "    for i, row in filtered_df.iterrows():\n",
    "        # Check if this row is close to any already kept row\n",
    "        is_close = False\n",
    "        for kept_idx in indices_to_keep:\n",
    "            kept_row = filtered_df.loc[kept_idx]\n",
    "            if (\n",
    "                abs(row[\"pos_x\"] - kept_row[\"pos_x\"]) < threshold\n",
    "                and abs(row[\"pos_y\"] - kept_row[\"pos_y\"]) < threshold\n",
    "            ):\n",
    "                is_close = True\n",
    "                break\n",
    "\n",
    "        # If not close to any kept row, keep this one\n",
    "        if not is_close:\n",
    "            indices_to_keep.append(i)\n",
    "\n",
    "    # Return filtered dataframe with only the kept indices\n",
    "    return filtered_df.loc[indices_to_keep].sort_index()\n",
    "\n",
    "\n",
    "results_60S_df = filter_close_results(results_60S_df, threshold=10)\n",
    "results_40S_df = filter_close_results(results_40S_df, threshold=10)\n",
    "constrained_40S_df = filter_close_results(constrained_40S_df, threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976614e6",
   "metadata": {},
   "source": [
    "## Helper functions for slab creation and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab25088",
   "metadata": {},
   "source": [
    "### Creating slab with translations and rotations\n",
    "\n",
    "Here, the slab is created to be the same size as the original micrograph if it were down-sampled.\n",
    "This means the slab can be directly overlaid on the micrograph to visualize structure position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d55a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_slab(\n",
    "    image_shape: tuple[int, int],\n",
    "    image_pixel_size: float,  # Angstroms\n",
    "    slab_pixel_size: float,  # Angstroms\n",
    "    slab_thickness: float,  # Angstroms\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Create an empty slab with the specified pixel size and thickness.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_shape : tuple[int, int]\n",
    "        Shape of the image (height, width).\n",
    "    image_pixel_size : float\n",
    "        Pixel size of the image, in Angstroms.\n",
    "    slab_pixel_size : float\n",
    "        Desired voxel size of the slab, in Angstroms (isotropic).\n",
    "    slab_thickness : float\n",
    "        Thickness of the slab, in Angstroms.\n",
    "    \"\"\"\n",
    "    # Slab spans the same physical area as the image, but will have a different\n",
    "    # voxel pitch.\n",
    "    height = image_shape[0] * image_pixel_size\n",
    "    width = image_shape[1] * image_pixel_size\n",
    "\n",
    "    slab_height = int(height / slab_pixel_size)\n",
    "    slab_width = int(width / slab_pixel_size)\n",
    "    slab_depth = int(slab_thickness / slab_pixel_size)\n",
    "\n",
    "    slab = np.zeros((slab_height, slab_width, slab_depth), dtype=np.float32)\n",
    "\n",
    "    return slab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847b32b",
   "metadata": {},
   "source": [
    "### Helper function to place a smaller volume into a larger volume\n",
    "\n",
    "Note that this operates on integer coordinates (no sub-voxel accuracy), nor does this handle complex bounds checking.\n",
    "It will just raise an error if the slab bounds are exceeded.\n",
    "\n",
    "Also note that the rotation format is 'xyz' rather than the typical 'ZYZ' Euler angle format used by Leopard-EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3d9c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_into_larger_volume(\n",
    "    small_volume: np.ndarray,\n",
    "    large_volume: np.ndarray,\n",
    "    position: tuple[int, int, int],\n",
    "    orientation: tuple[float, float, float]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Transform a small volume and place it into a larger volume.\n",
    "\n",
    "    NOTE: The orientations are in ZYZ format, volumes are in ZYX format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    small_volume : np.ndarray\n",
    "        The small volume to be placed, shape (depth, height, width) in ZYX format.\n",
    "    large_volume : np.ndarray\n",
    "        The larger volume into which the small volume will be placed, shape\n",
    "        (depth, height, width) in ZYX format.\n",
    "    position : tuple[int, int, int]\n",
    "        The (z, y, x) position in the larger volume where the small volume will be placed.\n",
    "    orientation : tuple[float, float, float]\n",
    "        The rotation angles (in degrees) for ZYZ Euler angles.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The larger volume with the small volume placed and rotated inside it.\n",
    "    \"\"\"\n",
    "    # Calculate the position in the larger volume (only integer coordinates)\n",
    "    z, y, x = position\n",
    "    z_end = z + small_volume.shape[0]\n",
    "    y_end = y + small_volume.shape[1]\n",
    "    x_end = x + small_volume.shape[2]\n",
    "\n",
    "    # Check if the small volume fits into the larger volume\n",
    "    if (\n",
    "        z < 0\n",
    "        or y < 0\n",
    "        or x < 0\n",
    "        or z_end > large_volume.shape[0]\n",
    "        or y_end > large_volume.shape[1]\n",
    "        or x_end > large_volume.shape[2]\n",
    "    ):\n",
    "        print(f\"Position: {position}\")\n",
    "        print(f\"Small volume shape: {small_volume.shape}\")\n",
    "        print(f\"Larger volume shape: {large_volume.shape}\")\n",
    "        raise ValueError(\"Volume is out of bounds!\")\n",
    "\n",
    "    # Sequentially rotate the small volume (ZYZ Euler angles)\n",
    "    # For ZYX format: axes (0,1,2) correspond to (Z,Y,X)\n",
    "    phi, theta, psi = orientation\n",
    "    volume_rotated = rotate(small_volume, -phi, axes=(1, 2), reshape=False, order=2)  # Rotation around Z\n",
    "    volume_rotated = rotate(volume_rotated, theta, axes=(0, 2), reshape=False, order=2)  # Rotation around Y\n",
    "    volume_rotated = rotate(volume_rotated, -psi, axes=(0, 1), reshape=False, order=2)  # Rotation around Z\n",
    "\n",
    "    # Place the rotated small volume into the larger volume\n",
    "    large_volume[z:z_end, y:y_end, x:x_end] += volume_rotated\n",
    "\n",
    "    return large_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc47596",
   "metadata": {},
   "source": [
    "### Helper function to render volume from results DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5afeaa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_slab_from_results_df(\n",
    "    template_volume: np.ndarray,\n",
    "    results_df: pd.DataFrame,\n",
    "    image_shape: tuple[int, int],\n",
    "    image_pixel_size: float,\n",
    "    slab_pixel_size: float,\n",
    "    slab_z_min: float = None,\n",
    "    slab_z_max: float = None,\n",
    "    use_refined_columns: bool = True,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Takes in a results_df DataFrame and constructs a slab for the volume.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    template_volume : np.ndarray\n",
    "        The template volume to be placed into the slab, shape (depth, height, width).\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame containing the results with columns 'pos_x', 'pos_y', 'relative_defocus',\n",
    "        'phi', 'theta', and 'psi'.\n",
    "    image_shape : tuple[int, int]\n",
    "        Shape of the image (height, width) that the slab will cover.\n",
    "    image_pixel_size : float\n",
    "        Pixel size of the image, in Angstroms.\n",
    "    slab_pixel_size : float\n",
    "        Desired voxel size of the slab, in Angstroms (isotropic).\n",
    "    slab_z_min : float, optional\n",
    "        Minimum Z position of the slab in Angstroms. If None, it is calculated\n",
    "        from the results_df.\n",
    "    slab_z_max : float, optional\n",
    "        Maximum Z position of the slab in Angstroms. If None, it is calculated\n",
    "        from the results_df.\n",
    "    use_refined_columns : bool, optional\n",
    "        If True, then preference is given to refined columns in the results_df.\n",
    "        If False, the original columns are used. Falls back to original columns\n",
    "        if the refined columns are not present.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The constructed slab containing the placed template volumes, shape\n",
    "        (slab_height, slab_width, slab_depth).\n",
    "    \"\"\"\n",
    "    pos_x_col = \"pos_x\"\n",
    "    pos_y_col = \"pos_y\"\n",
    "    phi_col = \"phi\"\n",
    "    theta_col = \"theta\"\n",
    "    psi_col = \"psi\"\n",
    "    relative_defocus_col = \"relative_defocus\"\n",
    "    if use_refined_columns:\n",
    "        if (\n",
    "            \"refined_pos_x\" in results_df.columns\n",
    "            and \"refined_pos_y\" in results_df.columns\n",
    "            and \"refined_phi\" in results_df.columns\n",
    "            and \"refined_theta\" in results_df.columns\n",
    "            and \"refined_psi\" in results_df.columns\n",
    "            and \"refined_relative_defocus\" in results_df.columns\n",
    "        ):\n",
    "            pos_x_col = \"refined_pos_x\"\n",
    "            pos_y_col = \"refined_pos_y\"\n",
    "            phi_col = \"refined_phi\"\n",
    "            theta_col = \"refined_theta\"\n",
    "            psi_col = \"refined_psi\"\n",
    "            relative_defocus_col = \"refined_relative_defocus\"\n",
    "        else:\n",
    "            print(\"Refined columns not found, using original columns.\")\n",
    "\n",
    "    # Find minimum/maximum defocus values to set zero position\n",
    "    min_defocus = results_df[relative_defocus_col].min()\n",
    "    max_defocus = results_df[relative_defocus_col].max()\n",
    "\n",
    "    # Use defocus range as slab thickness if not provided\n",
    "    if slab_z_min is None:\n",
    "        slab_z_min = min_defocus\n",
    "    if slab_z_max is None:\n",
    "        slab_z_max = max_defocus\n",
    "\n",
    "    slab_thickness = slab_z_max - slab_z_min \n",
    "    slab_thickness += (template_volume.shape[0] + 1) * slab_pixel_size\n",
    "\n",
    "    slab = create_empty_slab(\n",
    "        image_shape=image_shape,\n",
    "        image_pixel_size=image_pixel_size,\n",
    "        slab_pixel_size=slab_pixel_size,\n",
    "        slab_thickness=slab_thickness,\n",
    "    )\n",
    "\n",
    "    for i, row in results_df.iterrows():\n",
    "        print(f\"Placing volume {i + 1} of {len(results_df)}\")\n",
    "        # Get full image position and convert to slab coordinates\n",
    "        position = [\n",
    "            row[pos_x_col] * image_pixel_size,\n",
    "            row[pos_y_col] * image_pixel_size,\n",
    "            float(row[relative_defocus_col]) - slab_z_min,\n",
    "        ]\n",
    "        position = np.array(position)\n",
    "        position = np.round(position / slab_pixel_size).astype(int)\n",
    "        position = tuple(position.tolist())\n",
    "\n",
    "        orientation = [row[phi_col], row[theta_col], row[psi_col]]\n",
    "\n",
    "        slab = place_into_larger_volume(\n",
    "            small_volume=template_volume,\n",
    "            large_volume=slab,\n",
    "            position=position,\n",
    "            orientation=orientation,\n",
    "        )\n",
    "\n",
    "    # # Slab is in XYZ format, but MRC are generally defined in ZYX format.\n",
    "    # slab = np.transpose(slab, (2, 0, 1))  # Change to ZYX format\n",
    "\n",
    "    return slab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f19d8b",
   "metadata": {},
   "source": [
    "## Generating slabs for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b93c1ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaled 60S template voxel shape: 4.992 Angstroms\n"
     ]
    }
   ],
   "source": [
    "template_60S_rescaled, px_60S_rescaled = torch_fourier_rescale.fourier_rescale_3d(\n",
    "    image=torch.from_numpy(template_60S),\n",
    "    source_spacing=px_60S,\n",
    "    target_spacing=5.0,\n",
    ")\n",
    "px_60S_rescaled = px_60S_rescaled[0].item()\n",
    "\n",
    "print(f\"Rescaled 60S template voxel shape: {px_60S_rescaled:.3f} Angstroms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cb93d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaled 40S template voxel shape: 4.992 Angstroms\n"
     ]
    }
   ],
   "source": [
    "template_40S_rescaled, px_40S_rescaled = torch_fourier_rescale.fourier_rescale_3d(\n",
    "    image=torch.from_numpy(template_40S),\n",
    "    source_spacing=px_40S,\n",
    "    target_spacing=5.0,\n",
    ")\n",
    "px_40S_rescaled = px_40S_rescaled[0].item()\n",
    "\n",
    "print(f\"Rescaled 40S template voxel shape: {px_40S_rescaled:.3f} Angstroms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c271dc",
   "metadata": {},
   "source": [
    "### Finding minimum/maximum relative defocus for each dataframe\n",
    "\n",
    "Since we want the z depth of particles to be consistent across all generated slabs, we look at the minimum and maximum relative defocus columns in each of the DataFrames taking the most extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a089bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-980.0, 740.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slab_z_min = min(\n",
    "    results_60S_df[\"refined_relative_defocus\"].min(),\n",
    "    results_40S_df[\"refined_relative_defocus\"].min(),\n",
    "    constrained_40S_df[\"refined_relative_defocus\"].min(),\n",
    ").item()\n",
    "slab_z_max = max(\n",
    "    results_60S_df[\"refined_relative_defocus\"].max(),\n",
    "    results_40S_df[\"refined_relative_defocus\"].max(),\n",
    "    constrained_40S_df[\"refined_relative_defocus\"].max(),\n",
    ").item()\n",
    "slab_z_min, slab_z_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a61bb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placing volume 1 of 111\n",
      "Placing volume 2 of 111\n",
      "Placing volume 3 of 111\n",
      "Placing volume 4 of 111\n",
      "Placing volume 5 of 111\n",
      "Placing volume 6 of 111\n",
      "Placing volume 7 of 111\n",
      "Placing volume 8 of 111\n",
      "Placing volume 9 of 111\n",
      "Placing volume 10 of 111\n",
      "Placing volume 11 of 111\n",
      "Placing volume 12 of 111\n",
      "Placing volume 13 of 111\n",
      "Placing volume 14 of 111\n",
      "Placing volume 15 of 111\n",
      "Placing volume 16 of 111\n",
      "Placing volume 17 of 111\n",
      "Placing volume 18 of 111\n",
      "Placing volume 19 of 111\n",
      "Placing volume 20 of 111\n",
      "Placing volume 21 of 111\n",
      "Placing volume 22 of 111\n",
      "Placing volume 23 of 111\n",
      "Placing volume 24 of 111\n",
      "Placing volume 25 of 111\n",
      "Placing volume 26 of 111\n",
      "Placing volume 27 of 111\n",
      "Placing volume 28 of 111\n",
      "Placing volume 29 of 111\n",
      "Placing volume 30 of 111\n",
      "Placing volume 31 of 111\n",
      "Placing volume 32 of 111\n",
      "Placing volume 33 of 111\n",
      "Placing volume 34 of 111\n",
      "Placing volume 35 of 111\n",
      "Placing volume 36 of 111\n",
      "Placing volume 37 of 111\n",
      "Placing volume 38 of 111\n",
      "Placing volume 39 of 111\n",
      "Placing volume 40 of 111\n",
      "Placing volume 41 of 111\n",
      "Placing volume 42 of 111\n",
      "Placing volume 43 of 111\n",
      "Placing volume 44 of 111\n",
      "Placing volume 45 of 111\n",
      "Placing volume 46 of 111\n",
      "Placing volume 47 of 111\n",
      "Placing volume 48 of 111\n",
      "Placing volume 49 of 111\n",
      "Placing volume 50 of 111\n",
      "Placing volume 51 of 111\n",
      "Placing volume 52 of 111\n",
      "Placing volume 53 of 111\n",
      "Placing volume 54 of 111\n",
      "Placing volume 55 of 111\n",
      "Placing volume 56 of 111\n",
      "Placing volume 57 of 111\n",
      "Placing volume 58 of 111\n",
      "Placing volume 59 of 111\n",
      "Placing volume 60 of 111\n",
      "Placing volume 61 of 111\n",
      "Placing volume 62 of 111\n",
      "Placing volume 63 of 111\n",
      "Placing volume 64 of 111\n",
      "Placing volume 65 of 111\n",
      "Placing volume 66 of 111\n",
      "Placing volume 67 of 111\n",
      "Placing volume 68 of 111\n",
      "Placing volume 69 of 111\n",
      "Placing volume 70 of 111\n",
      "Placing volume 71 of 111\n",
      "Placing volume 72 of 111\n",
      "Placing volume 73 of 111\n",
      "Placing volume 74 of 111\n",
      "Placing volume 75 of 111\n",
      "Placing volume 76 of 111\n",
      "Placing volume 77 of 111\n",
      "Placing volume 78 of 111\n",
      "Placing volume 79 of 111\n",
      "Placing volume 80 of 111\n",
      "Placing volume 81 of 111\n",
      "Placing volume 82 of 111\n",
      "Placing volume 83 of 111\n",
      "Placing volume 84 of 111\n",
      "Placing volume 85 of 111\n",
      "Placing volume 86 of 111\n",
      "Placing volume 87 of 111\n",
      "Placing volume 88 of 111\n",
      "Placing volume 91 of 111\n",
      "Placing volume 92 of 111\n",
      "Placing volume 94 of 111\n",
      "Placing volume 95 of 111\n",
      "Placing volume 97 of 111\n",
      "Placing volume 100 of 111\n",
      "Placing volume 101 of 111\n",
      "Placing volume 102 of 111\n",
      "Placing volume 103 of 111\n",
      "Placing volume 104 of 111\n",
      "Placing volume 105 of 111\n",
      "Placing volume 106 of 111\n",
      "Placing volume 107 of 111\n",
      "Placing volume 109 of 111\n",
      "Placing volume 110 of 111\n",
      "Placing volume 112 of 111\n",
      "Placing volume 113 of 111\n",
      "Placing volume 114 of 111\n",
      "Placing volume 115 of 111\n",
      "Placing volume 117 of 111\n",
      "Placing volume 118 of 111\n",
      "Placing volume 119 of 111\n",
      "Placing volume 124 of 111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(863, 863, 441)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slab_60S = construct_slab_from_results_df(\n",
    "    template_volume=template_60S_rescaled,\n",
    "    results_df=results_60S_df,\n",
    "    image_shape=(\n",
    "        img.shape[0] + template_60S.shape[0],\n",
    "        img.shape[1] + template_60S.shape[1],\n",
    "    ),\n",
    "    image_pixel_size=px_60S,\n",
    "    slab_pixel_size=px_60S_rescaled,\n",
    "    slab_z_max=slab_z_max,\n",
    "    slab_z_min=slab_z_min,\n",
    ")\n",
    "slab_60S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d975d64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slab saved to slab_60S_constrained.mrc\n"
     ]
    }
   ],
   "source": [
    "# Save the slab to a MRC file\n",
    "slab_60S_mrc_path = \"slab_60S_constrained.mrc\"\n",
    "with mrcfile.new(slab_60S_mrc_path, overwrite=True) as mrc:\n",
    "    mrc.set_data(slab_60S.astype(np.float32))\n",
    "    mrc.voxel_size = (px_60S_rescaled, px_60S_rescaled, px_60S_rescaled)\n",
    "    mrc.update_header_from_data()\n",
    "    print(f\"Slab saved to {slab_60S_mrc_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5343ac77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined columns not found, using original columns.\n",
      "Placing volume 1 of 14\n",
      "Placing volume 2 of 14\n",
      "Placing volume 3 of 14\n",
      "Placing volume 4 of 14\n",
      "Placing volume 5 of 14\n",
      "Placing volume 6 of 14\n",
      "Placing volume 7 of 14\n",
      "Placing volume 8 of 14\n",
      "Placing volume 9 of 14\n",
      "Placing volume 10 of 14\n",
      "Placing volume 11 of 14\n",
      "Placing volume 12 of 14\n",
      "Placing volume 13 of 14\n",
      "Placing volume 14 of 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(863, 863, 441)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slab_40S = construct_slab_from_results_df(\n",
    "    template_volume=template_40S_rescaled,\n",
    "    results_df=results_40S_df,\n",
    "    image_shape=(\n",
    "        img.shape[0] + template_40S.shape[0],\n",
    "        img.shape[1] + template_40S.shape[1],\n",
    "    ),\n",
    "    image_pixel_size=px_40S,\n",
    "    slab_pixel_size=px_40S_rescaled,\n",
    "    slab_z_max=slab_z_max,\n",
    "    slab_z_min=slab_z_min,\n",
    ")\n",
    "slab_40S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "019892b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slab saved to slab_40S_unconstrained.mrc\n"
     ]
    }
   ],
   "source": [
    "# Save the slab to a MRC file\n",
    "slab_40S_mrc_path = \"slab_40S_unconstrained.mrc\"\n",
    "with mrcfile.new(slab_40S_mrc_path, overwrite=True) as mrc:\n",
    "    mrc.set_data(slab_40S.astype(np.float32))\n",
    "    mrc.voxel_size = (px_40S_rescaled, px_40S_rescaled, px_40S_rescaled)\n",
    "    mrc.update_header_from_data()\n",
    "    print(f\"Slab saved to {slab_40S_mrc_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f324130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placing volume 1 of 76\n",
      "Placing volume 2 of 76\n",
      "Placing volume 3 of 76\n",
      "Placing volume 4 of 76\n",
      "Placing volume 5 of 76\n",
      "Placing volume 6 of 76\n",
      "Placing volume 7 of 76\n",
      "Placing volume 8 of 76\n",
      "Placing volume 9 of 76\n",
      "Placing volume 10 of 76\n",
      "Placing volume 11 of 76\n",
      "Placing volume 12 of 76\n",
      "Placing volume 13 of 76\n",
      "Placing volume 14 of 76\n",
      "Placing volume 15 of 76\n",
      "Placing volume 16 of 76\n",
      "Placing volume 17 of 76\n",
      "Placing volume 18 of 76\n",
      "Placing volume 19 of 76\n",
      "Placing volume 20 of 76\n",
      "Placing volume 21 of 76\n",
      "Placing volume 22 of 76\n",
      "Placing volume 23 of 76\n",
      "Placing volume 24 of 76\n",
      "Placing volume 25 of 76\n",
      "Placing volume 26 of 76\n",
      "Placing volume 27 of 76\n",
      "Placing volume 28 of 76\n",
      "Placing volume 29 of 76\n",
      "Placing volume 30 of 76\n",
      "Placing volume 31 of 76\n",
      "Placing volume 32 of 76\n",
      "Placing volume 33 of 76\n",
      "Placing volume 34 of 76\n",
      "Placing volume 35 of 76\n",
      "Placing volume 36 of 76\n",
      "Placing volume 37 of 76\n",
      "Placing volume 38 of 76\n",
      "Placing volume 39 of 76\n",
      "Placing volume 40 of 76\n",
      "Placing volume 41 of 76\n",
      "Placing volume 42 of 76\n",
      "Placing volume 43 of 76\n",
      "Placing volume 44 of 76\n",
      "Placing volume 45 of 76\n",
      "Placing volume 46 of 76\n",
      "Placing volume 47 of 76\n",
      "Placing volume 48 of 76\n",
      "Placing volume 49 of 76\n",
      "Placing volume 50 of 76\n",
      "Placing volume 51 of 76\n",
      "Placing volume 52 of 76\n",
      "Placing volume 53 of 76\n",
      "Placing volume 54 of 76\n",
      "Placing volume 55 of 76\n",
      "Placing volume 56 of 76\n",
      "Placing volume 57 of 76\n",
      "Placing volume 58 of 76\n",
      "Placing volume 59 of 76\n",
      "Placing volume 60 of 76\n",
      "Placing volume 61 of 76\n",
      "Placing volume 62 of 76\n",
      "Placing volume 63 of 76\n",
      "Placing volume 64 of 76\n",
      "Placing volume 65 of 76\n",
      "Placing volume 66 of 76\n",
      "Placing volume 67 of 76\n",
      "Placing volume 69 of 76\n",
      "Placing volume 71 of 76\n",
      "Placing volume 72 of 76\n",
      "Placing volume 75 of 76\n",
      "Placing volume 76 of 76\n",
      "Placing volume 78 of 76\n",
      "Placing volume 80 of 76\n",
      "Placing volume 82 of 76\n",
      "Placing volume 83 of 76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(863, 863, 441)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slab_40S_constrained = construct_slab_from_results_df(\n",
    "    template_volume=template_40S_rescaled,\n",
    "    results_df=constrained_40S_df,\n",
    "    image_shape=(\n",
    "        img.shape[0] + template_40S.shape[0],\n",
    "        img.shape[1] + template_40S.shape[1],\n",
    "    ),\n",
    "    image_pixel_size=px_40S,\n",
    "    slab_pixel_size=px_40S_rescaled,\n",
    "    slab_z_max=slab_z_max,\n",
    "    slab_z_min=slab_z_min,\n",
    ")\n",
    "slab_40S_constrained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7d19f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slab saved to slab_40S_constrained.mrc\n"
     ]
    }
   ],
   "source": [
    "# Save the slab to a MRC file\n",
    "slab_40S_constrained_path = \"slab_40S_constrained.mrc\"\n",
    "with mrcfile.new(slab_40S_constrained_path, overwrite=True) as mrc:\n",
    "    mrc.set_data(slab_40S_constrained.astype(np.float32))\n",
    "    mrc.voxel_size = (px_40S_rescaled, px_40S_rescaled, px_40S_rescaled)\n",
    "    mrc.update_header_from_data()\n",
    "    print(f\"Slab saved to {slab_40S_constrained_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2dtm-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
